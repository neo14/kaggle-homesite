## Kaggle-Titanic
Kaggle上的一个入门题目，属于二分类问题。
### 问题背景
泰坦尼克号中一个经典的场面就是豪华游艇倒了，大家都惊恐逃生，可是救生艇的数量有限，不可能让大家都同时获救，
这时候副船长发话了：lady and kid first！这并不是一个随意安排的逃生顺序，而是某些人有优先逃生的特权，比如贵族，女人，小孩的。 
那么现在问题来了：给出一些船员的个人信息以及存活状况，让参赛者根据这些信息训练出合适的模型并预测其他人的存活状况。
### 数据集

字段之间用逗号隔开，每行数据包含的字段如下：
```
PassengerID  
Survived(存活与否)
Pclass（客舱等级）
Name（姓名）
Sex（性别）
Age（年龄）
SibSp（亲戚和配偶在船数量）
Parch（父母孩子的在船数量）
Ticket（票编号）
Fare（价格）
Cabin（客舱位置）
Embarked（上船的港口编号）
```
### 评估方式
比赛通过准确率指标评估模型优劣   
$$precision=\frac{\sum_{i=1}^NI(\hat{y}_i==y_i)}{N}$$  
y^i表示预测值，yi表示实际值

### 模型选择
常见的分类模型有：SVM，LR，Navie Bayesian，CART以及由CART演化而来的树类模型，Random Forest，GBDT，最近详细研究了GBDT，
发现它的拟合能力近乎完美，而且在调整了参数之后可以降低过拟合的影响，据说高斯过程的拟合能力也比不过它，这次就决定直接采用GBDT来做主模型。

### 特征选择
第一反应就是名字，Ticket，Cabin这些字段太零散，基本上每个人的都不一样，感觉并没有什么用。
Cabin这一维度的特征更是缺失很严重，所以暂且不考虑Ticket，Cabin的这些特征 。 
反观Name这个特征，看似并没有什么用，大家的名字都不一样，实际上从GBDT的调试过程来看，这个特征的使用频率很高的。
通俗地说，Name可以给模型提供一定的泛化能力，比如一家人面临危机的时候，大家肯定都先找到自己的家人一起逃生，所以一家人的存活状况相关性肯定很高的。
所以我引入名字特征的方式并不是直接引入名字，而是考虑和当前预测人的名字同姓的存活率。
另外还有个背景问题，就是逃生的时候，女士优先逃生，这个时候家人就分开了，所以名字这个特征还要考虑性别，综合来说就是性别＋姓的存活率作为一个特征。 
另外，还增了相应类别的存活率这些特征，比如各种性别的存活率以及各种等级的存活率，之前请教过别人，
这种把分类ID扔进模型之后有必要把所属ID的百分比扔进去吗？还是有必要的，前者是“是什么类别“的因素，后者是“有多少存活比例“的因素，是和有不能混为一谈。

### 特征缺失
数据中的某列特征丢失了在模型训练的时候是很正常的。目前了解到的解决方案是：
直接扔掉这行数据（数据多任性）
对于缺失的数据统一给一个新的label，让模型来学出给这种label多大的权值（感觉数据量大的情况才能训出来）
这个特征的缺失率很高 
直接扔掉这列特征
搞一个模型来拟合这维度的特征
给一个默认值，这个值可以是均值，或者众数。（感觉这个方法其实和上一个方法的拟合很相似，通过均值or众数来拟合其实可理解为人工的最大似然。

### 使用scikit-learn的随机数森林实践
sklearn-random-forest.py
